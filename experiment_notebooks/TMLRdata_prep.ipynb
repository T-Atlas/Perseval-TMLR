{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140bf154-2fa4-4719-ae95-713f55735241",
   "metadata": {},
   "source": [
    "# Notes\n",
    "## Dataset details:\n",
    "[OpenAI reddit dataset](https://huggingface.co/datasets/openai/summarize_from_feedback)\n",
    "2 subsets:\n",
    "1. Axis\n",
    "User(raters) rate a summary across different axis(\"overall\", \"accuracy\", \"coverage\", \"coherence\", \"compatible\") \n",
    "2. Comparison\n",
    "USer is given a document and summary pair and ask to rate which one is better.user also gives his rating a confidence score\n",
    "\n",
    "|            | Train  | Valid                    | Test           |\n",
    "| ---------- | ------ | ------------------------ | -------------- |\n",
    "| Comparison | Reddit | Reddit<br>CNN/Daily mail |                |\n",
    "| Axis       | x      | Reddit                   | CNN/Daily mail |\n",
    "|            |        |                          |                |\n",
    "\n",
    "## Appropriation\n",
    "\n",
    "End goal: We need user history(series of clicks/skips) as well as user generated document summaries. OpenAI dataset has none.  Hence the appropriation.\n",
    "### User generated summaries:  \n",
    "We use Axis subset for the same. User is evaluating different model/policy summaries given a document. His maximum rating summary is consdired as if he himself is generating it.  \n",
    "**Subset used:** : comparison  \n",
    "**split used:** validation  \n",
    "\n",
    "### User click/skip history\n",
    "We use comparison subset for the same. Given a document user is given multiple pairs to pick better summary and mentions his confidence in that choice. We take mean of those confidence scores as a proxy to how easily user get\"s it and make decision around that document. We use this to separate the documents which he might click(high mean confidence) or skip(low mean confidence)  \n",
    "**Subset used:** : comparisons  \n",
    "**split used:** validation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801ffc8-748d-4561-a77d-6f1616b17a1e",
   "metadata": {},
   "source": [
    "## Desired output format for model input\n",
    "1. news.tsv\n",
    "News ID: document id  \n",
    "Category:  category  \n",
    "Headline: actual title  \n",
    "News Body: document text  \n",
    "\n",
    "\n",
    "\n",
    "2. personalized_test.tsv (contains user click history)   \n",
    "userid: user id  \n",
    "clicknewsID: document ids clicked by user   \n",
    "posnewID: document ids user was asked to summarize  \n",
    "rewrite_titles: personlized summary generated by user        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3afb29c-2b4d-4313-b45e-2a64eb3a726b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d49e91d-fd5f-4b34-90a1-bc9999725cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d807a-3055-43c8-b851-2933f3e5b4c5",
   "metadata": {},
   "source": [
    "# Prepare master data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02417681-6cb0-48d2-b206-fbd14cfb0ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['info', 'summary', 'worker', 'batch', 'split'], dtype='object')\n",
      "unique_users: (32,)\n",
      "unique_docs: (1038,)\n",
      "Index(['info', 'summaries', 'choice', 'worker', 'batch', 'split', 'extra'], dtype='object')\n",
      "unique_users: (63,)\n",
      "unique_docs: (6714,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6320, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_master_data(hf_dataset=\"openai/summarize_from_feedback\", subset=\"axis\", split=\"validation\"):\n",
    "    if subset:\n",
    "        ds = load_dataset(\"openai/summarize_from_feedback\", subset)\n",
    "    else:\n",
    "        ds = load_dataset(\"openai/summarize_from_feedback\")\n",
    "     \n",
    "    df = ds[split].to_pandas()\n",
    "    print(df.columns)  \n",
    "    unique_users = df[\"worker\"].drop_duplicates().shape\n",
    "    print(f\"unique_users: {unique_users}\")\n",
    "    unique_docs = df[\"info\"].drop_duplicates().shape\n",
    "    print(f\"unique_docs: {unique_docs}\")\n",
    "    # flatten data\n",
    "#     Category: category\n",
    "# Headline: actual title\n",
    "# News Body: document text\n",
    "    df[\"News ID\"] = df[\"info\"].apply(lambda x: x[\"id\"])\n",
    "    df[\"News Body\"] = df[\"info\"].apply(lambda x: x[\"post\"])\n",
    "    df[\"Headline\"] = df[\"info\"].apply(lambda x: x[\"title\"])\n",
    "    df[\"Category\"] =  df[\"info\"].apply(lambda x: x[\"subreddit\"])\n",
    "    df = df[~df[\"Category\"].isna()]\n",
    "    df = df[[\"News ID\", \"News Body\", \"Headline\", \"Category\"]]\n",
    "    df = df.drop_duplicates(\"News ID\")\n",
    "    return df\n",
    "    \n",
    "\n",
    "# df_comparison\n",
    "master_df.shape\n",
    "\n",
    "# ds_history = load_dataset(\"openai/summarize_from_feedback\", \"comparisons\")\n",
    "# df_history = ds_history[\"validation\"].to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb2606bd-990a-402c-9cf2-785aa822cb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['info', 'summary', 'worker', 'batch', 'split'], dtype='object')\n",
      "unique_users: (32,)\n",
      "unique_docs: (1038,)\n",
      "Index(['info', 'summaries', 'choice', 'worker', 'batch', 'split', 'extra'], dtype='object')\n",
      "unique_users: (63,)\n",
      "unique_docs: (6714,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_axis = get_master_data(hf_dataset=\"openai/summarize_from_feedback\", subset=\"axis\", split=\"validation\") # unique_users: (32,),  unique_docs: (1038,)\n",
    "df_comparison = get_master_data(hf_dataset=\"openai/summarize_from_feedback\", subset=\"comparisons\", split=\"validation\") # unique_users: (63,), unique_docs: (6714,)\n",
    "\n",
    "master_df = pd.concat([df_axis, df_comparison], axis=0)# df_axis.append(df_comparison, ignore_index=True)\n",
    "master_df = master_df.drop_duplicates(\"News ID\")\n",
    "\n",
    "master_df.to_csv(\"news.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d544b8b-a327-4aa5-991f-5b52b5c60575",
   "metadata": {},
   "source": [
    "# Prepare personalized data\n",
    "User summaries are simulated from `axis` subset, `validation` split.  \n",
    "User click histories are simulated from `comparison` subset, `validation` split.  \n",
    "Note: user document pair that occures in summaries is excluded from click history.\n",
    "\n",
    "In short:\n",
    "1. User clicks is the documents for which user rates it\"s different pairs with mean confidence > 5  \n",
    "2. User summaries are the model/policy summary for which he rated highest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1fdbbef9-c870-458c-a7bb-ac7b82340302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uid', 'doc_id', 'summary_text'], dtype='object')\n",
      "user_summaries.columns: Index(['uid', 'doc_id', 'summary_text'], dtype='object')\n",
      "user_clicks.columns: Index(['uid', 'doc_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def get_user_summaries(hf_dataset=\"openai/summarize_from_feedback\", subset=\"axis\", split=\"validation\", rating_summ_threshold=5.0):\n",
    "    if subset:\n",
    "        ds_history = load_dataset(hf_dataset, subset)\n",
    "    else:\n",
    "        hf_history = load_dataset(hf_dataset)\n",
    "    df = ds_history[\"validation\"].to_pandas()\n",
    "    # flatten\n",
    "    df =df.rename(columns={\"worker\":\"uid\"})\n",
    "    df[\"doc_id\"] = df[\"info\"].apply(lambda x: x[\"id\"])\n",
    "\n",
    "    df[\"summary_text\"] = df[\"summary\"].apply(lambda x: x[\"text\"])\n",
    "    df[\"summary_rating\"] = df[\"summary\"].apply(lambda x: x[\"axes\"][\"overall\"])\n",
    "    df[\"summary_model\"] = df[\"summary\"].apply(lambda x: x[\"policy\"])\n",
    "    df = df[[\"uid\",\"doc_id\", \"summary_model\", \"summary_text\", \"summary_rating\"]] \n",
    "    idx = df.groupby(['doc_id', 'uid'])['summary_rating'].idxmax()\n",
    "    df = df.loc[idx]\n",
    "\n",
    "    # filter above threshold as clicks\n",
    "    df_usummaries = df[df[\"summary_rating\"] > rating_summ_threshold]\n",
    "    df_usummaries = df_usummaries[[\"uid\", \"doc_id\", \"summary_text\"]]\n",
    "    print(df_usummaries.columns)\n",
    "    # df_usummaries = df_usummaries.groupby(\"uid\").aggregate({'doc_id': lambda x: x.tolist(), \"summary_text\":  lambda x: \";;\".join(x.tolist())})\n",
    "    # print(df_click)\n",
    "    # df_usummaries.rename({\"doc_id\": \"posnewID\", \"summary_text\":\"rewrite_titles\"})\n",
    "    # posnewID: document ids user was asked to summarize  \n",
    "    # rewrite_titles: personlized summary generated by user \n",
    "    return df_usummaries\n",
    "\n",
    "\n",
    "def get_user_clicks(hf_dataset=\"openai/summarize_from_feedback\", subset=\"comparisons\", split=\"validation\", rating_click_threshold=5.0):\n",
    "    if subset:\n",
    "        ds_history = load_dataset(hf_dataset, subset)\n",
    "    else:\n",
    "        hf_history = load_dataset(hf_dataset)\n",
    "    df_history = ds_history[\"validation\"].to_pandas()\n",
    "    # flatten\n",
    "    df_history = df_history.rename(columns={\"worker\":\"uid\"})\n",
    "    df_history[\"doc_id\"] = df_history[\"info\"].apply(lambda x: x[\"id\"])\n",
    "    df_history[\"doc_text\"] = df_history[\"info\"].apply(lambda x: x[\"post\"])\n",
    "    df_history[\"subreddit\"] = df_history[\"info\"].apply(lambda x: x[\"subreddit\"])\n",
    "    \n",
    "    # filter out non subreddit \n",
    "    df_history = df_history[~df_history[\"subreddit\"].isna()]\n",
    "    \n",
    "    df_history[\"confidence\"] = df_history[\"extra\"].apply(lambda x: x[\"confidence\"])\n",
    "    history_candidates = df_history[[\"uid\",\"doc_id\", \"confidence\"]].groupby([\"doc_id\", \"uid\"]).aggregate(\"mean\")[\"confidence\"]\n",
    "     \n",
    "    history_candidates = history_candidates.reset_index()\n",
    "    history_candidates = history_candidates[history_candidates[\"confidence\"]> rating_click_threshold]\n",
    "    history_candidates = history_candidates[[\"uid\", \"doc_id\"]]\n",
    "    # history_candidates= history_candidates[[\"uid\", \"doc_id\"]].groupby(\"uid\").aggregate({\"doc_id\": lambda x: x.to_list()})\n",
    "    # history_candidates = history_candidates.reset_index()\n",
    "    \n",
    "    return history_candidates\n",
    "    \n",
    "\n",
    "# consolidate history\n",
    "user_summaries = get_user_summaries()\n",
    "print(f\"user_summaries.columns: {user_summaries.columns}\")\n",
    "\n",
    "user_clicks = get_user_clicks()\n",
    "print(f\"user_clicks.columns: {user_clicks.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915069a-374f-45c2-aa07-419ebbff329b",
   "metadata": {},
   "source": [
    "## exclude user summary docs from click docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "95601871-6645-4f6f-b207-ff7b90833dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>clicknewsID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3AFaFd3w9NjDGnO51kupLyK1N44DQ2</td>\n",
       "      <td>t3_10uftj,t3_115df2,t3_11fvr8,t3_11z6b6,t3_121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43gHDyCi222pTzozK8X47V7YdLit7P</td>\n",
       "      <td>t3_12a7za,t3_14bpbp,t3_1aoiah,t3_1i2p7t,t3_1j6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ</td>\n",
       "      <td>t3_10de6c,t3_1cq11l,t3_1glbok,t3_1ke2y7,t3_1p0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4voZkkCJyOCnpQ5f8WFf5unLW1dSjC</td>\n",
       "      <td>t3_19b8cq,t3_19zkjr,t3_1aoiah,t3_1bal64,t3_1k8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6TDC3rcGcujIOhfdq3356VhN4NzveC</td>\n",
       "      <td>t3_12yk7r,t3_13cdkb,t3_1krnth,t3_2coxcy,t3_2f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rmgbTjW1stlproQnuHE2bUpK78Jxle</td>\n",
       "      <td>t3_103e7p,t3_10erz1,t3_10rz2c,t3_137uxi,t3_14y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>sC4a4UNRMSYCGopXr3K8znnyna6TVh</td>\n",
       "      <td>t3_11yrlm,t3_1hanb5,t3_1p0iwc,t3_1s4igw,t3_1tq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>thott7XepukYSbOL2QgSlyXd0rgHvr</td>\n",
       "      <td>t3_10x2g2,t3_115svb,t3_11yrlm,t3_12md1j,t3_138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>t3_11fvr8,t3_11yrlm,t3_120wzc,t3_12lkx5,t3_12m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>zKV8BFGy60O0q7102ALF84S6Jo5i4q</td>\n",
       "      <td>t3_10n7mt,t3_1199u9,t3_11q5nj,t3_11wlmg,t3_11y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               uid  \\\n",
       "0   3AFaFd3w9NjDGnO51kupLyK1N44DQ2   \n",
       "1   43gHDyCi222pTzozK8X47V7YdLit7P   \n",
       "2   44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ   \n",
       "3   4voZkkCJyOCnpQ5f8WFf5unLW1dSjC   \n",
       "4   6TDC3rcGcujIOhfdq3356VhN4NzveC   \n",
       "..                             ...   \n",
       "56  rmgbTjW1stlproQnuHE2bUpK78Jxle   \n",
       "57  sC4a4UNRMSYCGopXr3K8znnyna6TVh   \n",
       "58  thott7XepukYSbOL2QgSlyXd0rgHvr   \n",
       "59  uvzut5OK2bvei9zoCDdktcfLENYioY   \n",
       "60  zKV8BFGy60O0q7102ALF84S6Jo5i4q   \n",
       "\n",
       "                                          clicknewsID  \n",
       "0   t3_10uftj,t3_115df2,t3_11fvr8,t3_11z6b6,t3_121...  \n",
       "1   t3_12a7za,t3_14bpbp,t3_1aoiah,t3_1i2p7t,t3_1j6...  \n",
       "2   t3_10de6c,t3_1cq11l,t3_1glbok,t3_1ke2y7,t3_1p0...  \n",
       "3   t3_19b8cq,t3_19zkjr,t3_1aoiah,t3_1bal64,t3_1k8...  \n",
       "4   t3_12yk7r,t3_13cdkb,t3_1krnth,t3_2coxcy,t3_2f2...  \n",
       "..                                                ...  \n",
       "56  t3_103e7p,t3_10erz1,t3_10rz2c,t3_137uxi,t3_14y...  \n",
       "57  t3_11yrlm,t3_1hanb5,t3_1p0iwc,t3_1s4igw,t3_1tq...  \n",
       "58  t3_10x2g2,t3_115svb,t3_11yrlm,t3_12md1j,t3_138...  \n",
       "59  t3_11fvr8,t3_11yrlm,t3_120wzc,t3_12lkx5,t3_12m...  \n",
       "60  t3_10n7mt,t3_1199u9,t3_11q5nj,t3_11wlmg,t3_11y...  \n",
       "\n",
       "[61 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_clicks\n",
    "# user_summaries\n",
    "user_doc_tuples = [tuple(x) for x in  user_summaries[[\"uid\", \"doc_id\"]].values]\n",
    "user_doc_tuples\n",
    "\n",
    "user_clicks[\"summary_flag\"] = user_clicks.apply(lambda x: (x[\"uid\"],x[\"doc_id\"]) in user_doc_tuples, axis=1)\n",
    "user_clicks = user_clicks[~user_clicks[\"summary_flag\"]]\n",
    "user_clicks = user_clicks.groupby(\"uid\").aggregate({\"doc_id\": lambda x: \",\".join(list(x.to_list()))})\n",
    "user_clicks = user_clicks.reset_index()\n",
    "user_clicks = user_clicks.rename(columns={\"doc_id\": \"clicknewsID\"})\n",
    "user_clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb66a98-1a17-4b9d-9b5e-9a2bfa44b699",
   "metadata": {},
   "source": [
    "## consolidate users that have both history as well as summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5db37ed3-c3a7-4bf4-93c7-2542e12804f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_summaries.columns: Index(['uid', 'doc_id', 'summary_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f\"user_summaries.columns: {user_summaries.columns}\")\n",
    "user_summaries = user_summaries.groupby(\"uid\").aggregate({\"doc_id\":lambda x: \",\".join(x.to_list()), \"summary_text\": lambda x:\";;\".join(x.to_list())}, axis=1)\n",
    "user_summaries = user_summaries.reset_index()\n",
    "user_summaries = user_summaries.rename(columns={\"doc_id\": \"posnewID\", \"summary_text\": \"rewrite_titles\"})\n",
    "user_summaries\n",
    "personalized_test = pd.merge(user_clicks, user_summaries, on=[\"uid\"])\n",
    "personalized_test = personalized_test.rename(columns={\"uid\":\"userid\"}) \n",
    "personalized_test.to_csv(\"personalized_test.csv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
